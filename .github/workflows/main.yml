name: Build patched V8 d8 (6 reusable workers)

on:
  schedule:
    - cron: "0 2 * * *"
  workflow_dispatch:
    inputs:
      max_per_run:
        description: "本次最多处理多少个新版本（默认 20）"
        required: false
        default: "20"

permissions:
  contents: write
  actions: write

concurrency:
  group: build-patched-v8
  cancel-in-progress: false

env:
  V8_REPO: https://github.com/v8/v8.git
  MIN_VERSION: 12.0.1
  PATCH_FILE: patch.diff
  EXPECTED_PATCH_FILE_COUNT: "6"
  MAX_PER_RUN: ${{ github.event.inputs.max_per_run || '20' }}
  SLOTS_PER_OS: 3

jobs:
  determine-versions:
    name: Determine unprocessed versions
    runs-on: ubuntu-latest
    outputs:
      versions_json: ${{ steps.determine.outputs.versions }}
      has_versions: ${{ steps.determine.outputs.has_versions }}
      leftover_total: ${{ steps.determine.outputs.leftover_total }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Ensure tracking JSON
        run: |
          mkdir -p public
          [ -f public/version.json ] || echo "[]" > public/version.json
          [ -f public/failed.json ] || echo "[]" > public/failed.json
      - name: Python version
        run: python3 --version
      - name: Determine versions
        id: determine
        run: python3 determine_versions.py
      - name: Echo outputs
        run: |
          echo "versions=${{ steps.determine.outputs.versions }}"
          echo "has_versions=${{ steps.determine.outputs.has_versions }}"
          echo "leftover=${{ steps.determine.outputs.leftover_total }}"

  build:
    name: Build slot ${{ matrix.slot }} / ${{ matrix.os }}
    needs: determine-versions
    if: needs.determine-versions.outputs.has_versions == 'true'
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest]
        slot: [0,1,2]
    env:
      ALL_VERSIONS: ${{ needs.determine-versions.outputs.versions_json }}
      SLOT_INDEX: ${{ matrix.slot }}
      SLOTS_PER_OS: 3
      DEPOT_TOOLS_WIN_TOOLCHAIN: "0"
      GYP_MSVS_VERSION: "2022"
    steps:
      - name: Checkout infra repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Write versions.json
        run: |
          echo '${{ env.ALL_VERSIONS }}' > versions.json
          cat versions.json

      - name: Partition versions for this slot
        id: partition
        run: |
          python3 partition_versions.py
        env:
          VERSIONS_JSON: ${{ env.ALL_VERSIONS }}
          SLOT_INDEX: ${{ env.SLOT_INDEX }}
          SLOTS_PER_OS: ${{ env.SLOTS_PER_OS }}

      - name: Stop early if no versions
        if: steps.partition.outputs.has_any == 'false'
        run: echo "No versions assigned to this slot."

      - name: Prepare (Linux)
        if: runner.os == 'Linux' && steps.partition.outputs.has_any == 'true'
        shell: bash
        run: |
          set -eux
          sudo apt-get update
          sudo apt-get install -y python3 python-is-python3 build-essential clang libglib2.0-dev flex bison git curl unzip pkg-config patch
          git clone https://chromium.googlesource.com/chromium/tools/depot_tools.git
          export PATH="$PWD/depot_tools:$PATH"
          echo "$PWD/depot_tools" >> $GITHUB_PATH
          python --version
          gclient --version

      - name: Prepare (Windows)
        if: runner.os == 'Windows' && steps.partition.outputs.has_any == 'true'
        shell: pwsh
        run: |
          chcp 65001
          git clone https://chromium.googlesource.com/chromium/tools/depot_tools.git
          $env:PATH = "$PWD\depot_tools;" + $env:PATH
          "$PWD\depot_tools" | Out-File -FilePath $env:GITHUB_PATH -Encoding utf8 -Append
          "PYTHONUTF8=1"                 | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
          "PYTHONIOENCODING=UTF-8"       | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
          "DEPOT_TOOLS_WIN_TOOLCHAIN=0"  | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
          "GYP_MSVS_VERSION=2022"        | Out-File -FilePath $env:GITHUB_ENV -Encoding utf8 -Append
          python --version
          gclient --version

      - name: Initial sync (GitHub main repo)
        if: steps.partition.outputs.has_any == 'true'
        shell: bash
        run: |
          set -eux
          gclient config --name v8 --unmanaged https://github.com/v8/v8.git
          gclient sync --nohooks -D --no-history
          gclient runhooks

      - name: Copy helper scripts
        if: steps.partition.outputs.has_any == 'true'
        run: |
          cp apply_patch.py v8/
          cp patch.diff v8/
          cp partition_versions.py v8/ || true

      - name: Process versions (loop)
        if: steps.partition.outputs.has_any == 'true'
        shell: bash
        env:
          ASSIGNED_JSON: ${{ steps.partition.outputs.assigned_json }}
        run: |
          set -e
          echo "Assigned versions: $ASSIGNED_JSON"
          python3 - <<'PY'
import os, json, subprocess, shlex, sys

assigned = json.loads(os.environ.get("ASSIGNED_JSON","[]"))
if not assigned:
    print("No versions to process.")
    sys.exit(0)

def run(cmd, cwd=None, check=True, reason=None):
    print(f"[RUN] {cmd}")
    r = subprocess.run(cmd, cwd=cwd, shell=True)
    if check and r.returncode != 0:
        raise RuntimeError(reason or f"Command failed: {cmd}")
    return r.returncode

success = []
failed = []
failure_reasons = []  # list of (version, reason)

EXPECTED_FILES = {
    "src/d8/d8.cc",
    "src/d8/d8.h",
    "src/diagnostics/objects-printer.cc",
    "src/objects/string.cc",
    "src/snapshot/code-serializer.cc",
    "src/snapshot/deserializer.cc"
}

for v in assigned:
    print(f"\n==== Processing {v} ====")
    try:
        try:
            run("git -C v8 fetch --tags", reason="fetch-tags")
            run(f"git -C v8 checkout {shlex.quote(v)}", reason="checkout-tag")
        except Exception as e:
            failed.append(v); failure_reasons.append((v,"checkout"))
            print(f"[FAIL-{v}] checkout: {e}")
            run("git -C v8 checkout .", check=False)
            continue

        try:
            run("gclient sync -D --no-history", reason="sync-deps")
        except Exception as e:
            failed.append(v); failure_reasons.append((v,"sync"))
            print(f"[FAIL-{v}] sync: {e}")
            run("git -C v8 checkout .", check=False)
            continue

        try:
            run("gclient runhooks", reason="runhooks")
        except Exception as e:
            failed.append(v); failure_reasons.append((v,"runhooks"))
            print(f"[FAIL-{v}] runhooks: {e}")
            run("git -C v8 checkout .", check=False)
            continue

        # Apply patch
        rc = subprocess.run("python3 apply_patch.py --patch patch.diff --verbose --report apply_patch_report.txt",
                            cwd="v8", shell=True).returncode
        if rc != 0:
            failed.append(v); failure_reasons.append((v,"patch"))
            print(f"[FAIL-{v}] patch apply failed rc={rc}")
            run("git -C v8 checkout .", check=False)
            continue

        # Validate diff
        diff_out = subprocess.check_output("git -C v8 diff --name-only", shell=True, text=True)
        if not any(line.strip() in EXPECTED_FILES for line in diff_out.splitlines()):
            failed.append(v); failure_reasons.append((v,"patch-nochange"))
            print(f"[FAIL-{v}] no expected file modified after patch.")
            run("git -C v8 checkout .", check=False)
            continue

        # Build
        build_dir = f"out.gn/x64.release.{v.replace('.', '_')}"
        try:
            run(f"python tools/dev/v8gen.py {build_dir} -- v8_enable_disassembler=true v8_enable_object_print=true is_component_build=false",
                cwd="v8", reason="build-config")
        except Exception as e:
            failed.append(v); failure_reasons.append((v,"build-config"))
            print(f"[FAIL-{v}] build-config: {e}")
            run("git -C v8 checkout .", check=False)
            continue

        try:
            run(f"ninja -C {build_dir} d8", cwd="v8", reason="build-ninja")
        except Exception as e:
            failed.append(v); failure_reasons.append((v,"build-ninja"))
            print(f"[FAIL-{v}] build-ninja: {e}")
            run("git -C v8 checkout .", check=False)
            continue

        # Collect artifact
        import platform, shutil
        os.makedirs("artifacts", exist_ok=True)
        os_name = "Windows" if platform.system().lower().startswith("win") else "Linux"
        target_dir = f"artifacts/d8-{v}-{os_name}"
        os.makedirs(target_dir, exist_ok=True)
        binary_name = "d8.exe" if os_name == "Windows" else "d8"
        src_bin = os.path.join("v8", build_dir, binary_name)
        if not os.path.exists(src_bin):
            failed.append(v); failure_reasons.append((v,"binary-missing"))
            print(f"[FAIL-{v}] binary missing")
            run("git -C v8 checkout .", check=False)
            continue
        shutil.copy2(src_bin, os.path.join(target_dir, binary_name))
        report_src = os.path.join("v8","apply_patch_report.txt")
        if os.path.exists(report_src):
            shutil.copy2(report_src, os.path.join(target_dir, "apply_patch_report.txt"))

        # Clean modifications for next version
        run("git -C v8 checkout .", check=False)
        success.append(v)
        print(f"[OK] {v}")
    except Exception as e:
        failed.append(v); failure_reasons.append((v,"exception"))
        print(f"[FAIL-{v}] exception: {e}")
        run("git -C v8 checkout .", check=False)

print("SUCCESS:", success)
print("FAILED:", failed)
with open("success_versions.txt","w",encoding="utf-8") as f:
    for s in success: f.write(s+"\n")
with open("failed_versions.txt","w",encoding="utf-8") as f:
    for s in failed: f.write(s+"\n")
with open("failed_reasons.txt","w",encoding="utf-8") as f:
    for v,r in failure_reasons:
        f.write(f"{v}\t{r}\n")
PY

      - name: Upload batch artifacts
        if: steps.partition.outputs.has_any == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: build-batch-${{ matrix.os }}-slot${{ matrix.slot }}
          path: |
            artifacts/**
            success_versions.txt
            failed_versions.txt
            failed_reasons.txt
          retention-days: 7

  aggregate-and-release:
    name: Aggregate & release
    needs: [determine-versions, build]
    if: needs.determine-versions.outputs.has_versions == 'true'
    runs-on: ubuntu-latest
    outputs:
      leftover_total: ${{ needs.determine-versions.outputs.leftover_total }}
    steps:
      - uses: actions/checkout@v4
        with:
            fetch-depth: 0

      - name: Download all batch artifacts
        uses: actions/download-artifact@v4
        with:
          path: downloaded

      - name: Install tools
        run: |
          sudo apt-get update
          sudo apt-get install -y jq
          gh --version || true

      - name: Merge success/failed and reasons
        run: |
          set -e
          mkdir -p public
          [ -f public/version.json ] || echo "[]" > public/version.json
          [ -f public/failed.json ] || echo "[]" > public/failed.json
          [ -f public/failed_detailed.json ] || echo "[]" > public/failed_detailed.json
          touch _all_success.txt _all_failed.txt _all_failed_reasons.txt
          find downloaded -type f -name success_versions.txt -exec cat {} \; >> _all_success.txt || true
          find downloaded -type f -name failed_versions.txt -exec cat {} \; >> _all_failed.txt || true
          find downloaded -type f -name failed_reasons.txt -exec cat {} \; >> _all_failed_reasons.txt || true
          sort -u -o _all_success.txt _all_success.txt
            # _all_failed 不去重前先排序
          sort -u -o _all_failed.txt _all_failed.txt

          echo "Success versions:"; cat _all_success.txt || true
          echo "Failed versions:";  cat _all_failed.txt || true
          echo "Failed reasons raw:"; head -100 _all_failed_reasons.txt || true

          # 更新 failed.json (版本数组)
          while read -r v; do
            [ -z "$v" ] && continue
            jq -e --arg v "$v" '.[] | select(. == $v)' public/failed.json >/dev/null || \
              jq --arg v "$v" '. + [$v]' public/failed.json > public/.tmp && mv public/.tmp public/failed.json
          done < _all_failed.txt

          # 更新 failed_detailed.json (对象数组)
          # 读取现有
          tmp_failed=$(mktemp)
          cp public/failed_detailed.json "$tmp_failed"
          python3 - <<'PY'
import json,sys
detail_path="public/failed_detailed.json"
with open(detail_path,"r",encoding="utf-8") as f:
    try:
        data=json.load(f)
        if not isinstance(data,list): data=[]
    except:
        data=[]
existing={d["version"]:d for d in data if isinstance(d,dict) and "version" in d}
# 读新的 reason 列表
new=[]
with open("_all_failed_reasons.txt","r",encoding="utf-8") as f:
    for line in f:
        line=line.rstrip()
        if not line: continue
        if "\t" in line:
            v,r=line.split("\t",1)
        else:
            v,r=line,"unknown"
        if v in existing: # 保留首次原因
            continue
        new.append({"version":v,"reason":r})
data=list(existing.values())+new
with open(detail_path,"w",encoding="utf-8") as f:
    json.dump(data,f,ensure_ascii=False,indent=2)
PY
          echo "failed_detailed.json:"; cat public/failed_detailed.json

      - name: Reconstruct per-version artifact dirs
        run: |
          set -e
          mkdir -p stage
          find downloaded -type f -name d8 -o -name d8.exe | while read -r bin; do
            base=$(basename "$(dirname "$bin")")
            ver="${base#d8-}"
            if echo "$base" | grep -q "\-Linux$"; then
              ver="${ver%-Linux}"
              tgt="stage/d8-${ver}-Linux"
              mkdir -p "$tgt"
              cp "$bin" "$tgt/d8"
              rep_dir=$(dirname "$bin")
              [ -f "$rep_dir/apply_patch_report.txt" ] && cp "$rep_dir/apply_patch_report.txt" "$tgt/"
            elif echo "$base" | grep -q "\-Windows$"; then
              ver="${ver%-Windows}"
              tgt="stage/d8-${ver}-Windows"
              mkdir -p "$tgt"
              cp "$bin" "$tgt/d8.exe"
              rep_dir=$(dirname "$bin")
              [ -f "$rep_dir/apply_patch_report.txt" ] && cp "$rep_dir/apply_patch_report.txt" "$tgt/"
            fi
          done
          echo "Stage structure:"
          find stage -maxdepth 2 -type f -print

      - name: Create releases & update version.json
        env:
          ALL_VERSIONS: ${{ needs.determine-versions.outputs.versions_json }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -e
          [ -f public/version.json ] || echo "[]" > public/version.json
          updated=false
          for v in $(echo "${ALL_VERSIONS}" | jq -r '.[]'); do
            [ -z "$v" ] && continue
            L="stage/d8-${v}-Linux/d8"
            W="stage/d8-${v}-Windows/d8.exe"
            if [ ! -f "$L" ] || [ ! -f "$W" ]; then
              echo "Skip release for $v (missing one platform artifact)."
              continue
            fi
            mkdir -p "public/$v"
            cp "$L" "public/$v/d8-linux"
            cp "$W" "public/$v/d8-windows.exe"
            if gh release view "$v" >/dev/null 2>&1; then
              echo "Release $v already exists."
            else
              gh release create "$v" \
                "public/$v/d8-linux" \
                "public/$v/d8-windows.exe" \
                --title "$v" \
                --notes "Patched d8 for V8 $v (batched multi-version build)."
            fi
            if ! jq -e --arg v "$v" '.[] | select(. == $v)' public/version.json >/dev/null; then
              jq --arg v "$v" '. + [$v]' public/version.json > public/.tmp && mv public/.tmp public/version.json
              updated=true
            fi
          done
          if [ "$updated" = true ]; then
            jq '[.[]] | sort_by((split(".")+["0","0","0","0"])[0:4]|map(tonumber))' public/version.json > public/.tmp && mv public/.tmp public/version.json
          fi
          echo "version.json:"; cat public/version.json
          echo "failed.json:";  cat public/failed.json
          echo "failed_detailed.json:"; cat public/failed_detailed.json

      - name: Commit & push tracking
        run: |
          if git diff --quiet -- public; then
            echo "No tracking changes."
            exit 0
          fi
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add public
          git commit -m "Update tracking (batch workers + reasons) [skip ci]"
          git push

  trigger-next-batch:
    name: Trigger next batch if leftovers
    needs: [aggregate-and-release]
    if: needs.aggregate-and-release.outputs.leftover_total != '' && needs.aggregate-and-release.outputs.leftover_total != '0'
    runs-on: ubuntu-latest
    steps:
      - name: Dispatch next
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          NEXT_MAX: ${{ env.MAX_PER_RUN }}
        run: |
          echo "Triggering next batch..."
          REF="${GITHUB_REF_NAME:-${GITHUB_REF##*/}}"
          if [ -z "$REF" ]; then
            REF=$(curl -s -H "Authorization: Bearer $GITHUB_TOKEN" \
              https://api.github.com/repos/${GITHUB_REPOSITORY} | jq -r '.default_branch')
          fi
          curl -s -X POST \
            -H "Authorization: Bearer $GITHUB_TOKEN" \
            -H "Accept: application/vnd.github+json" \
            https://api.github.com/repos/${GITHUB_REPOSITORY}/actions/workflows/main.yml/dispatches \
            -d "{\"ref\":\"${REF}\",\"inputs\":{\"max_per_run\":\"${NEXT_MAX}\"}}"
          echo "Next batch dispatched."
